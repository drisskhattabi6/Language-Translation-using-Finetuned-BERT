{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13018304,"sourceType":"datasetVersion","datasetId":8242264}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"e1a54e64-6880-4539-a99b-92a6d7450080","cell_type":"markdown","source":"## Fine-tune a BERT-based encoder-decoder for English -> Arabic translation","metadata":{}},{"id":"894ec163-41ea-47a9-b7fe-4196df81e89c","cell_type":"code","source":"%%capture\n!pip install evaluate sacrebleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T15:36:38.659612Z","iopub.execute_input":"2025-09-11T15:36:38.660269Z","iopub.status.idle":"2025-09-11T15:36:44.059841Z","shell.execute_reply.started":"2025-09-11T15:36:38.660235Z","shell.execute_reply":"2025-09-11T15:36:44.058784Z"}},"outputs":[],"execution_count":2},{"id":"1c2d16e6-59e3-4194-a99c-3ed711477e1a","cell_type":"code","source":"import re\nimport os\nimport argparse\nfrom typing import List\nimport inspect\n\nimport pandas as pd\nimport numpy as np\nimport torch\n\n# HF libs\nfrom datasets import Dataset\nimport evaluate\nimport transformers\nfrom transformers import (\n    AutoTokenizer,\n    EncoderDecoderModel,\n    DataCollatorForSeq2Seq,\n    TrainingArguments,\n    Trainer,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T15:36:44.061988Z","iopub.execute_input":"2025-09-11T15:36:44.062254Z","iopub.status.idle":"2025-09-11T15:37:13.925680Z","shell.execute_reply.started":"2025-09-11T15:36:44.062232Z","shell.execute_reply":"2025-09-11T15:37:13.925114Z"}},"outputs":[{"name":"stderr","text":"2025-09-11 15:36:56.622565: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757605016.861169      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1757605016.930774      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"id":"1514da7a-80fa-490b-8b1c-2b0c959d3a4b","cell_type":"code","source":"# -------------------------\n# Small helpers / cleaning\n# -------------------------\nMAX_LENGTH = 64\n\ndef clean_arabic(text: str) -> str:\n    if not isinstance(text, str):\n        return \"\"\n    text = re.sub(r\"[^\\u0600-\\u06FFa-zA-Z0-9\\s]\", \"\", text)\n    arabic_diacritics = re.compile(r\"[\\u0617-\\u061A\\u064B-\\u0652\\u0670\\u0653-\\u0655\\u06D6-\\u06ED]\")\n    text = re.sub(arabic_diacritics, \"\", text)\n    replacements = {\n        \"آ\": \"ا\", \"أ\": \"ا\", \"إ\": \"ا\", \"ٱ\": \"ا\",\n        \"ة\": \"ه\", \"ى\": \"ي\",\n        \"ؤ\": \"و\", \"ئ\": \"ي\", \"ء\": \"\",\n        \"ـ\": \"\",\n        \"٠\":\"0\",\"١\":\"1\",\"٢\":\"2\",\"٣\":\"3\",\"٤\":\"4\",\"٥\":\"5\",\"٦\":\"6\",\"٧\":\"7\",\"٨\":\"8\",\"٩\":\"9\"\n    }\n    for k, v in replacements.items():\n        text = text.replace(k, v)\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text\n\ndef normalize_sentence_series(series: pd.Series) -> pd.Series:\n    s = series.astype(str).str.strip()\n    s = s.str.replace(r'[^A-Za-z\\u0600-\\u06FF0-9\\s]+', '', regex=True)\n    s = s.str.normalize(\"NFC\")\n    s = s.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n    return s\n\ndef read_file(loc: str, lang1=\"eng\", lang2=\"ara\") -> pd.DataFrame:\n    df = pd.read_csv(loc, delimiter='\\t', header=None, quoting=3, engine=\"python\")\n    df = df.iloc[:, :2]\n    df.columns = [lang1, lang2]\n    df[lang2] = df[lang2].apply(clean_arabic)\n    df[lang1] = df[lang1].astype(str).str.replace(r\"[^\\w\\s]\", \"\", regex=True).str.strip()\n    df[lang1] = normalize_sentence_series(df[lang1])\n    df[lang2] = normalize_sentence_series(df[lang2])\n    df = df.dropna(subset=[lang1, lang2]).drop_duplicates(subset=[lang1, lang2]).reset_index(drop=True)\n    return df\n\ndef filter_by_max_len(df: pd.DataFrame, max_words: int=MAX_LENGTH) -> pd.DataFrame:\n    mask = (df['eng'].str.split().str.len() <= max_words) & (df['ara'].str.split().str.len() <= max_words)\n    return df[mask].reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T15:37:13.926384Z","iopub.execute_input":"2025-09-11T15:37:13.926983Z","iopub.status.idle":"2025-09-11T15:37:13.936284Z","shell.execute_reply.started":"2025-09-11T15:37:13.926955Z","shell.execute_reply":"2025-09-11T15:37:13.935576Z"}},"outputs":[],"execution_count":4},{"id":"dea030b3-e65a-427b-b5fb-2cd303f6b4e1","cell_type":"code","source":"# -------------------------\n# Tokenization & dataset\n# -------------------------\ndef build_hf_dataset(df: pd.DataFrame, tokenizer, src_col=\"eng\", tgt_col=\"ara\", max_source_length=MAX_LENGTH, max_target_length=MAX_LENGTH):\n    def preprocess_fn(examples):\n        inputs = examples[src_col]\n        targets = examples[tgt_col]\n        model_inputs = tokenizer(inputs, max_length=max_source_length, truncation=True, padding=\"max_length\")\n        # as_target_tokenizer context (works with modern tokenizers)\n        try:\n            with tokenizer.as_target_tokenizer():\n                labels = tokenizer(targets, max_length=max_target_length, truncation=True, padding=\"max_length\")\n        except Exception:\n            labels = tokenizer(targets, max_length=max_target_length, truncation=True, padding=\"max_length\")\n        model_inputs[\"labels\"] = labels[\"input_ids\"]\n        return model_inputs\n\n    ds = Dataset.from_pandas(df[[src_col, tgt_col]])\n    tokenized = ds.map(preprocess_fn, batched=True, remove_columns=[src_col, tgt_col])\n    return tokenized","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T15:37:13.937116Z","iopub.execute_input":"2025-09-11T15:37:13.937407Z","iopub.status.idle":"2025-09-11T15:37:13.962751Z","shell.execute_reply.started":"2025-09-11T15:37:13.937383Z","shell.execute_reply":"2025-09-11T15:37:13.962073Z"}},"outputs":[],"execution_count":5},{"id":"e9f4248d-96d5-4a90-b75d-415b5aa1aa51","cell_type":"code","source":"# -------------------------\n# Metrics\n# -------------------------\nsacrebleu = evaluate.load(\"sacrebleu\")\n\ndef postprocess_text(preds: List[str], labels: List[str]):\n    preds = [p.strip() for p in preds]\n    labels = [[l.strip()] for l in labels]\n    return preds, labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T15:37:13.964639Z","iopub.execute_input":"2025-09-11T15:37:13.964860Z","iopub.status.idle":"2025-09-11T15:37:14.550316Z","shell.execute_reply.started":"2025-09-11T15:37:13.964844Z","shell.execute_reply":"2025-09-11T15:37:14.549604Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83645ba450bd489fb6bc30bf018b7260"}},"metadata":{}}],"execution_count":6},{"id":"f600f2ff-c540-46d6-922a-4cd7790a4a4d","cell_type":"code","source":"class Args:\n    output_dir = \"./outputs\"\n    num_train_epochs = 3\n    per_device_train_batch_size = 8\n    per_device_eval_batch_size = 8\n    learning_rate = 5e-5\n    save_steps = 500\n    eval_steps = 500\n    max_source_length = 64\n    max_target_length = 64\n\nargs = Args()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T15:37:14.551060Z","iopub.execute_input":"2025-09-11T15:37:14.551560Z","iopub.status.idle":"2025-09-11T15:37:14.555826Z","shell.execute_reply.started":"2025-09-11T15:37:14.551542Z","shell.execute_reply":"2025-09-11T15:37:14.555146Z"}},"outputs":[],"execution_count":7},{"id":"4137773e-7e08-41c8-9385-361bcc9cd2d5","cell_type":"code","source":"# -------------------------\n# Main train function\n# -------------------------\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--data_path\", type=str, default=\"/kaggle/input/eng-ara/eng-ara.txt\")\n    parser.add_argument(\"--output_dir\", type=str, default=\"./bert-encdec-eng-ara\")\n    parser.add_argument(\"--num_train_epochs\", type=int, default=12)\n    parser.add_argument(\"--per_device_train_batch_size\", type=int, default=8)\n    parser.add_argument(\"--per_device_eval_batch_size\", type=int, default=8)\n    parser.add_argument(\"--learning_rate\", type=float, default=5e-5)\n    parser.add_argument(\"--max_source_length\", type=int, default=64)\n    parser.add_argument(\"--max_target_length\", type=int, default=64)\n    args = parser.parse_args([])\n\n    print(\"transformers version:\", transformers.__version__)\n    df = read_file(args.data_path, \"eng\", \"ara\")\n    df = filter_by_max_len(df, max_words=MAX_LENGTH)\n    print(f\"Total pairs after cleaning: {len(df)}\")\n    if len(df) == 0:\n        raise ValueError(\"No pairs after cleaning. Check dataset path/format.\")\n\n    # split\n    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n    train_df = df.iloc[: int(len(df) * 0.9)].reset_index(drop=True)\n    val_df = df.iloc[int(len(df) * 0.9):].reset_index(drop=True)\n    print(\"Train / Val sizes:\", len(train_df), len(val_df))\n\n    model_name = \"bert-base-multilingual-cased\"\n    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n    model = EncoderDecoderModel.from_encoder_decoder_pretrained(model_name, model_name)\n\n    # config tokens\n    model.config.decoder_start_token_id = tokenizer.cls_token_id or tokenizer.bos_token_id or tokenizer.cls_token_id\n    model.config.eos_token_id = tokenizer.sep_token_id or tokenizer.eos_token_id\n    model.config.pad_token_id = tokenizer.pad_token_id\n    model.config.max_length = args.max_target_length\n    model.config.vocab_size = model.config.encoder.vocab_size\n\n    tokenized_train = build_hf_dataset(train_df, tokenizer, \"eng\", \"ara\", args.max_source_length, args.max_target_length)\n    tokenized_val = build_hf_dataset(val_df, tokenizer, \"eng\", \"ara\", args.max_source_length, args.max_target_length)\n\n    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=\"longest\", label_pad_token_id=-100)\n\n    # compute_metrics\n    def compute_metrics(eval_preds):\n        preds, labels = eval_preds\n        if isinstance(preds, tuple):\n            preds = preds[0]\n        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n        decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n        result = sacrebleu.compute(predictions=decoded_preds, references=decoded_labels)\n        return {\"bleu\": result[\"score\"]}\n\n    # -------------------------\n    # Compatibility: detect transformers version\n    # -------------------------\n    tver = tuple(int(x) for x in transformers.__version__.split(\".\")[:2])\n    supported_args = inspect.signature(TrainingArguments).parameters\n\n    # Base kwargs for TrainingArguments (safe)\n    train_args_kwargs = {\n        \"output_dir\": args.output_dir,\n        \"num_train_epochs\": args.num_train_epochs,\n        \"per_device_train_batch_size\": args.per_device_train_batch_size,\n        \"per_device_eval_batch_size\": args.per_device_eval_batch_size,\n        \"learning_rate\": args.learning_rate,\n        \"save_total_limit\": 3,\n        \"fp16\": torch.cuda.is_available(),\n        # make training logging visible on Kaggle / notebooks\n        \"logging_steps\": 100 if \"logging_steps\" in supported_args else None,\n    }\n    # remove None values\n    train_args_kwargs = {k: v for k, v in train_args_kwargs.items() if v is not None}\n\n    # Add modern args if supported\n    if \"evaluation_strategy\" in supported_args:\n        train_args_kwargs[\"evaluation_strategy\"] = \"steps\"\n        train_args_kwargs[\"eval_steps\"] = getattr(args, \"eval_steps\", 500)\n    if \"save_steps\" in supported_args:\n        train_args_kwargs[\"save_steps\"] = getattr(args, \"save_steps\", 500)\n    if \"remove_unused_columns\" in supported_args:\n        train_args_kwargs[\"remove_unused_columns\"] = False\n    # disable reporting to wandb/other remote loggers so Kaggle output is immediate\n    if \"report_to\" in supported_args:\n        train_args_kwargs[\"report_to\"] = \"none\"\n\n    # Build TrainingArguments (this will automatically use the appropriate signature)\n    training_args = TrainingArguments(**train_args_kwargs)\n\n    # Build trainer kwargs:\n    trainer_kwargs = dict(\n        model=model,\n        args=training_args,\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        train_dataset=tokenized_train,\n        eval_dataset=tokenized_val,\n        compute_metrics=compute_metrics,\n    )\n\n    # Try to pass predict_with_generate to Trainer only if accepted\n    try:\n        trainer = Trainer(**trainer_kwargs, predict_with_generate=True)\n    except TypeError:\n        trainer = Trainer(**trainer_kwargs)\n\n    # Make logs visible and confirm device\n    import transformers as _tf\n    _tf.logging.set_verbosity_info()\n    print(\"Starting training — device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n    print(\"TrainingArguments:\", training_args)\n\n    # Start training (you can resume from checkpoint by passing resume_from_checkpoint=\"path\")\n    train_result = trainer.train()\n    print(\"Training finished. Saving model ...\")\n    trainer.save_model(args.output_dir)\n    tokenizer.save_pretrained(args.output_dir)\n\n\n    # Quick generation check\n    sample_texts = val_df['eng'].tolist()[:8]\n    inputs = tokenizer(sample_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=args.max_source_length).to(model.device)\n    # Use model.generate (works with EncoderDecoderModel)\n    generated_ids = model.generate(\n        input_ids=inputs[\"input_ids\"],\n        attention_mask=inputs[\"attention_mask\"],\n        max_length=args.max_target_length,\n        num_beams=4,\n        early_stopping=True,\n    )\n    preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n    for s, p, t in zip(sample_texts, preds, val_df['ara'].tolist()[:len(preds)]):\n        print(\"SRC:\", s)\n        print(\"PRED:\", p)\n        print(\"TGT :\", t)\n        print(\"---\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T15:37:14.556505Z","iopub.execute_input":"2025-09-11T15:37:14.556800Z","iopub.status.idle":"2025-09-11T15:37:14.574474Z","shell.execute_reply.started":"2025-09-11T15:37:14.556773Z","shell.execute_reply":"2025-09-11T15:37:14.573888Z"}},"outputs":[],"execution_count":8},{"id":"4b414888-b697-42e0-a086-68eeab869fde","cell_type":"code","source":"if __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T15:37:14.575055Z","iopub.execute_input":"2025-09-11T15:37:14.575254Z","iopub.status.idle":"2025-09-11T16:51:34.543709Z","shell.execute_reply.started":"2025-09-11T15:37:14.575240Z","shell.execute_reply":"2025-09-11T16:51:34.542377Z"}},"outputs":[{"name":"stdout","text":"transformers version: 4.52.4\nTotal pairs after cleaning: 12468\nTrain / Val sizes: 11221 1247\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45feaf1822004f74a194e7cd5b40a2f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4b5e9dfb65248c29b0a107eab39138c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b7b5c00d214423e93c12a8555486bcf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8828919979e64cbd887fa9536040289b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1634aaf36f564ad18e8e324ad335c9d7"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/11221 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80ab5e580bfc4144a71541aa39b434aa"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3959: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1247 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbaee3774f324b75805bc54be1ea8c28"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3959: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/tmp/ipykernel_36/2479664526.py:106: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(**trainer_kwargs, predict_with_generate=True)\n/tmp/ipykernel_36/2479664526.py:108: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(**trainer_kwargs)\n***** Running training *****\n  Num examples = 11,221\n  Num Epochs = 12\n  Instantaneous batch size per device = 8\n  Training with DataParallel so batch size has been adjusted to: 16\n  Total train batch size (w. parallel, distributed & accumulation) = 16\n  Gradient Accumulation steps = 1\n  Total optimization steps = 8,424\n  Number of trainable parameters = 384,194,811\n","output_type":"stream"},{"name":"stdout","text":"Starting training — device: cuda\nTrainingArguments: TrainingArguments(\n_n_gpu=2,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndo_eval=False,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=None,\neval_strategy=IntervalStrategy.NO,\neval_use_gather_object=False,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=1,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=None,\nhub_strategy=HubStrategy.EVERY_SAVE,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=5e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=passive,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./bert-encdec-eng-ara/runs/Sep11_15-37-28_5eb608e5484c,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=100,\nlogging_strategy=IntervalStrategy.STEPS,\nlr_scheduler_kwargs={},\nlr_scheduler_type=SchedulerType.LINEAR,\nmax_grad_norm=1.0,\nmax_steps=-1,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=12,\noptim=OptimizerNames.ADAMW_TORCH,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./bert-encdec-eng-ara,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=8,\nper_device_train_batch_size=8,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=False,\nreport_to=[],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./bert-encdec-eng-ara,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=True,\nsave_steps=500,\nsave_strategy=SaveStrategy.STEPS,\nsave_total_limit=3,\nseed=42,\nskip_memory_metrics=True,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=0,\nweight_decay=0.0,\n)\n","output_type":"stream"},{"name":"stderr","text":"We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n/usr/local/lib/python3.11/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:577: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='8424' max='8424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [8424/8424 1:13:58, Epoch 12/12]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>1.415200</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.724900</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.683300</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.641200</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.616600</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.621800</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.582000</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.555800</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.533900</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.512800</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.499400</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.500500</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.461000</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.462900</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.426000</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.422900</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.407000</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.393900</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>0.396800</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.398900</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>0.403400</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.343400</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>0.344300</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.340300</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.324900</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>0.343500</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>0.328300</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>0.324700</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>0.282300</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.276800</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>0.287600</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>0.290500</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>0.277100</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>0.280900</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.277700</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>0.232800</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>0.221800</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>0.238000</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>0.218300</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.240200</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>0.239600</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>0.237000</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>0.200900</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>0.195300</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.194700</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>0.195100</td>\n    </tr>\n    <tr>\n      <td>4700</td>\n      <td>0.192500</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>0.181800</td>\n    </tr>\n    <tr>\n      <td>4900</td>\n      <td>0.192500</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.169700</td>\n    </tr>\n    <tr>\n      <td>5100</td>\n      <td>0.166300</td>\n    </tr>\n    <tr>\n      <td>5200</td>\n      <td>0.159100</td>\n    </tr>\n    <tr>\n      <td>5300</td>\n      <td>0.153800</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>0.172800</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.161100</td>\n    </tr>\n    <tr>\n      <td>5600</td>\n      <td>0.163500</td>\n    </tr>\n    <tr>\n      <td>5700</td>\n      <td>0.132700</td>\n    </tr>\n    <tr>\n      <td>5800</td>\n      <td>0.134200</td>\n    </tr>\n    <tr>\n      <td>5900</td>\n      <td>0.140900</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.134100</td>\n    </tr>\n    <tr>\n      <td>6100</td>\n      <td>0.138100</td>\n    </tr>\n    <tr>\n      <td>6200</td>\n      <td>0.149000</td>\n    </tr>\n    <tr>\n      <td>6300</td>\n      <td>0.129900</td>\n    </tr>\n    <tr>\n      <td>6400</td>\n      <td>0.130200</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.121700</td>\n    </tr>\n    <tr>\n      <td>6600</td>\n      <td>0.114300</td>\n    </tr>\n    <tr>\n      <td>6700</td>\n      <td>0.112400</td>\n    </tr>\n    <tr>\n      <td>6800</td>\n      <td>0.127300</td>\n    </tr>\n    <tr>\n      <td>6900</td>\n      <td>0.110500</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.111000</td>\n    </tr>\n    <tr>\n      <td>7100</td>\n      <td>0.097900</td>\n    </tr>\n    <tr>\n      <td>7200</td>\n      <td>0.106000</td>\n    </tr>\n    <tr>\n      <td>7300</td>\n      <td>0.098500</td>\n    </tr>\n    <tr>\n      <td>7400</td>\n      <td>0.102900</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.098300</td>\n    </tr>\n    <tr>\n      <td>7600</td>\n      <td>0.102900</td>\n    </tr>\n    <tr>\n      <td>7700</td>\n      <td>0.099500</td>\n    </tr>\n    <tr>\n      <td>7800</td>\n      <td>0.087800</td>\n    </tr>\n    <tr>\n      <td>7900</td>\n      <td>0.086700</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.084800</td>\n    </tr>\n    <tr>\n      <td>8100</td>\n      <td>0.092200</td>\n    </tr>\n    <tr>\n      <td>8200</td>\n      <td>0.082100</td>\n    </tr>\n    <tr>\n      <td>8300</td>\n      <td>0.078300</td>\n    </tr>\n    <tr>\n      <td>8400</td>\n      <td>0.094300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Saving model checkpoint to ./bert-encdec-eng-ara/checkpoint-500\n/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3465: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 64}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-500/config.json\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-500/generation_config.json\nModel weights saved in ./bert-encdec-eng-ara/checkpoint-500/model.safetensors\ntokenizer config file saved in ./bert-encdec-eng-ara/checkpoint-500/tokenizer_config.json\nSpecial tokens file saved in ./bert-encdec-eng-ara/checkpoint-500/special_tokens_map.json\n/usr/local/lib/python3.11/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:577: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to ./bert-encdec-eng-ara/checkpoint-1000\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-1000/config.json\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-1000/generation_config.json\nModel weights saved in ./bert-encdec-eng-ara/checkpoint-1000/model.safetensors\ntokenizer config file saved in ./bert-encdec-eng-ara/checkpoint-1000/tokenizer_config.json\nSpecial tokens file saved in ./bert-encdec-eng-ara/checkpoint-1000/special_tokens_map.json\n/usr/local/lib/python3.11/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:577: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to ./bert-encdec-eng-ara/checkpoint-1500\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-1500/config.json\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-1500/generation_config.json\nModel weights saved in ./bert-encdec-eng-ara/checkpoint-1500/model.safetensors\ntokenizer config file saved in ./bert-encdec-eng-ara/checkpoint-1500/tokenizer_config.json\nSpecial tokens file saved in ./bert-encdec-eng-ara/checkpoint-1500/special_tokens_map.json\n/usr/local/lib/python3.11/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:577: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to ./bert-encdec-eng-ara/checkpoint-2000\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-2000/config.json\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-2000/generation_config.json\nModel weights saved in ./bert-encdec-eng-ara/checkpoint-2000/model.safetensors\ntokenizer config file saved in ./bert-encdec-eng-ara/checkpoint-2000/tokenizer_config.json\nSpecial tokens file saved in ./bert-encdec-eng-ara/checkpoint-2000/special_tokens_map.json\nDeleting older checkpoint [bert-encdec-eng-ara/checkpoint-500] due to args.save_total_limit\n/usr/local/lib/python3.11/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:577: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to ./bert-encdec-eng-ara/checkpoint-2500\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-2500/config.json\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-2500/generation_config.json\nModel weights saved in ./bert-encdec-eng-ara/checkpoint-2500/model.safetensors\ntokenizer config file saved in ./bert-encdec-eng-ara/checkpoint-2500/tokenizer_config.json\nSpecial tokens file saved in ./bert-encdec-eng-ara/checkpoint-2500/special_tokens_map.json\nDeleting older checkpoint [bert-encdec-eng-ara/checkpoint-1000] due to args.save_total_limit\n/usr/local/lib/python3.11/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:577: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to ./bert-encdec-eng-ara/checkpoint-3000\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-3000/config.json\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-3000/generation_config.json\nModel weights saved in ./bert-encdec-eng-ara/checkpoint-3000/model.safetensors\ntokenizer config file saved in ./bert-encdec-eng-ara/checkpoint-3000/tokenizer_config.json\nSpecial tokens file saved in ./bert-encdec-eng-ara/checkpoint-3000/special_tokens_map.json\nDeleting older checkpoint [bert-encdec-eng-ara/checkpoint-1500] due to args.save_total_limit\n/usr/local/lib/python3.11/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:577: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to ./bert-encdec-eng-ara/checkpoint-3500\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-3500/config.json\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-3500/generation_config.json\nModel weights saved in ./bert-encdec-eng-ara/checkpoint-3500/model.safetensors\ntokenizer config file saved in ./bert-encdec-eng-ara/checkpoint-3500/tokenizer_config.json\nSpecial tokens file saved in ./bert-encdec-eng-ara/checkpoint-3500/special_tokens_map.json\nDeleting older checkpoint [bert-encdec-eng-ara/checkpoint-2000] due to args.save_total_limit\n/usr/local/lib/python3.11/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:577: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to ./bert-encdec-eng-ara/checkpoint-4000\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-4000/config.json\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-4000/generation_config.json\nModel weights saved in ./bert-encdec-eng-ara/checkpoint-4000/model.safetensors\ntokenizer config file saved in ./bert-encdec-eng-ara/checkpoint-4000/tokenizer_config.json\nSpecial tokens file saved in ./bert-encdec-eng-ara/checkpoint-4000/special_tokens_map.json\nDeleting older checkpoint [bert-encdec-eng-ara/checkpoint-2500] due to args.save_total_limit\n/usr/local/lib/python3.11/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:577: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to ./bert-encdec-eng-ara/checkpoint-4500\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-4500/config.json\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-4500/generation_config.json\nModel weights saved in ./bert-encdec-eng-ara/checkpoint-4500/model.safetensors\ntokenizer config file saved in ./bert-encdec-eng-ara/checkpoint-4500/tokenizer_config.json\nSpecial tokens file saved in ./bert-encdec-eng-ara/checkpoint-4500/special_tokens_map.json\nDeleting older checkpoint [bert-encdec-eng-ara/checkpoint-3000] due to args.save_total_limit\n/usr/local/lib/python3.11/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:577: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to ./bert-encdec-eng-ara/checkpoint-5000\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-5000/config.json\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-5000/generation_config.json\nModel weights saved in ./bert-encdec-eng-ara/checkpoint-5000/model.safetensors\ntokenizer config file saved in ./bert-encdec-eng-ara/checkpoint-5000/tokenizer_config.json\nSpecial tokens file saved in ./bert-encdec-eng-ara/checkpoint-5000/special_tokens_map.json\nDeleting older checkpoint [bert-encdec-eng-ara/checkpoint-3500] due to args.save_total_limit\n/usr/local/lib/python3.11/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:577: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to ./bert-encdec-eng-ara/checkpoint-5500\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-5500/config.json\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-5500/generation_config.json\nModel weights saved in ./bert-encdec-eng-ara/checkpoint-5500/model.safetensors\ntokenizer config file saved in ./bert-encdec-eng-ara/checkpoint-5500/tokenizer_config.json\nSpecial tokens file saved in ./bert-encdec-eng-ara/checkpoint-5500/special_tokens_map.json\nDeleting older checkpoint [bert-encdec-eng-ara/checkpoint-4000] due to args.save_total_limit\n/usr/local/lib/python3.11/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:577: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to ./bert-encdec-eng-ara/checkpoint-6000\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-6000/config.json\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-6000/generation_config.json\nModel weights saved in ./bert-encdec-eng-ara/checkpoint-6000/model.safetensors\ntokenizer config file saved in ./bert-encdec-eng-ara/checkpoint-6000/tokenizer_config.json\nSpecial tokens file saved in ./bert-encdec-eng-ara/checkpoint-6000/special_tokens_map.json\nDeleting older checkpoint [bert-encdec-eng-ara/checkpoint-4500] due to args.save_total_limit\n/usr/local/lib/python3.11/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:577: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to ./bert-encdec-eng-ara/checkpoint-6500\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-6500/config.json\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-6500/generation_config.json\nModel weights saved in ./bert-encdec-eng-ara/checkpoint-6500/model.safetensors\ntokenizer config file saved in ./bert-encdec-eng-ara/checkpoint-6500/tokenizer_config.json\nSpecial tokens file saved in ./bert-encdec-eng-ara/checkpoint-6500/special_tokens_map.json\nDeleting older checkpoint [bert-encdec-eng-ara/checkpoint-5000] due to args.save_total_limit\n/usr/local/lib/python3.11/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:577: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to ./bert-encdec-eng-ara/checkpoint-7000\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-7000/config.json\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-7000/generation_config.json\nModel weights saved in ./bert-encdec-eng-ara/checkpoint-7000/model.safetensors\ntokenizer config file saved in ./bert-encdec-eng-ara/checkpoint-7000/tokenizer_config.json\nSpecial tokens file saved in ./bert-encdec-eng-ara/checkpoint-7000/special_tokens_map.json\nDeleting older checkpoint [bert-encdec-eng-ara/checkpoint-5500] due to args.save_total_limit\n/usr/local/lib/python3.11/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:577: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to ./bert-encdec-eng-ara/checkpoint-7500\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-7500/config.json\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-7500/generation_config.json\nModel weights saved in ./bert-encdec-eng-ara/checkpoint-7500/model.safetensors\ntokenizer config file saved in ./bert-encdec-eng-ara/checkpoint-7500/tokenizer_config.json\nSpecial tokens file saved in ./bert-encdec-eng-ara/checkpoint-7500/special_tokens_map.json\nDeleting older checkpoint [bert-encdec-eng-ara/checkpoint-6000] due to args.save_total_limit\n/usr/local/lib/python3.11/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:577: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to ./bert-encdec-eng-ara/checkpoint-8000\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-8000/config.json\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-8000/generation_config.json\nModel weights saved in ./bert-encdec-eng-ara/checkpoint-8000/model.safetensors\ntokenizer config file saved in ./bert-encdec-eng-ara/checkpoint-8000/tokenizer_config.json\nSpecial tokens file saved in ./bert-encdec-eng-ara/checkpoint-8000/special_tokens_map.json\nDeleting older checkpoint [bert-encdec-eng-ara/checkpoint-6500] due to args.save_total_limit\n/usr/local/lib/python3.11/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:577: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSaving model checkpoint to ./bert-encdec-eng-ara/checkpoint-8424\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-8424/config.json\nConfiguration saved in ./bert-encdec-eng-ara/checkpoint-8424/generation_config.json\nModel weights saved in ./bert-encdec-eng-ara/checkpoint-8424/model.safetensors\ntokenizer config file saved in ./bert-encdec-eng-ara/checkpoint-8424/tokenizer_config.json\nSpecial tokens file saved in ./bert-encdec-eng-ara/checkpoint-8424/special_tokens_map.json\nDeleting older checkpoint [bert-encdec-eng-ara/checkpoint-7000] due to args.save_total_limit\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nSaving model checkpoint to ./bert-encdec-eng-ara\nConfiguration saved in ./bert-encdec-eng-ara/config.json\nConfiguration saved in ./bert-encdec-eng-ara/generation_config.json\n","output_type":"stream"},{"name":"stdout","text":"Training finished. Saving model ...\n","output_type":"stream"},{"name":"stderr","text":"Model weights saved in ./bert-encdec-eng-ara/model.safetensors\ntokenizer config file saved in ./bert-encdec-eng-ara/tokenizer_config.json\nSpecial tokens file saved in ./bert-encdec-eng-ara/special_tokens_map.json\ntokenizer config file saved in ./bert-encdec-eng-ara/tokenizer_config.json\nSpecial tokens file saved in ./bert-encdec-eng-ara/special_tokens_map.json\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3832242952.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/2479664526.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_source_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;31m# Use model.generate (works with EncoderDecoderModel)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     generated_ids = model.generate(\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2377\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2378\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_special_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_has_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2380\u001b[0m         \u001b[0;31m# decoder-only models must use left-padding for batched generation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_prepare_special_tokens\u001b[0;34m(self, generation_config, kwargs_has_attention_mask, device)\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;31m# Sanity checks/warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdecoder_start_token_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2154\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2155\u001b[0m                 \u001b[0;34m\"`decoder_start_token_id` or `bos_token_id` has to be defined for encoder-decoder generation.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: `decoder_start_token_id` or `bos_token_id` has to be defined for encoder-decoder generation."],"ename":"ValueError","evalue":"`decoder_start_token_id` or `bos_token_id` has to be defined for encoder-decoder generation.","output_type":"error"}],"execution_count":9},{"id":"e423a514-718e-491c-a62d-83d7bc3e1551","cell_type":"code","source":"import pandas as pd\nimport torch\nfrom transformers import AutoTokenizer, EncoderDecoderModel\n\n# -------------------------\n# Load model + tokenizer\n# -------------------------\nmodel_name = \"/kaggle/working/bert-encdec-eng-ara/checkpoint-8424\" \ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = EncoderDecoderModel.from_pretrained(model_name)\n\n# Fix missing config values\nif model.config.decoder_start_token_id is None:\n    model.config.decoder_start_token_id = tokenizer.cls_token_id or tokenizer.bos_token_id\nif model.config.eos_token_id is None:\n    model.config.eos_token_id = tokenizer.sep_token_id or tokenizer.eos_token_id\nif model.config.pad_token_id is None:\n    model.config.pad_token_id = tokenizer.pad_token_id\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Force set special tokens for generation\nmodel.config.decoder_start_token_id = tokenizer.cls_token_id or 101\nmodel.config.eos_token_id = tokenizer.sep_token_id or 102\nmodel.config.pad_token_id = tokenizer.pad_token_id or 0\n\n# -------------------------\n# Load dataset\n# -------------------------\nfile_path = \"/kaggle/input/eng-ara/eng-ara.txt\" \ndf = pd.read_csv(file_path, sep=\"\\t\", header=None, usecols=[0,1], names=[\"eng\",\"ara\"])\n\n# Take 20 random samples\nsample_df = df.sample(20, random_state=42).reset_index(drop=True)\n\n# -------------------------\n# Prediction function\n# -------------------------\ndef translate(sentence, max_len=64):\n    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n    # outputs = model.generate(**inputs, max_length=max_len)\n    outputs = model.generate(\n        **inputs,\n        max_length=max_len,\n        decoder_start_token_id=model.config.decoder_start_token_id,\n        eos_token_id=model.config.eos_token_id,\n        pad_token_id=model.config.pad_token_id\n    )\n\n    pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return pred.strip()\n\n# -------------------------\n# Run predictions\n# -------------------------\nfor i, row in sample_df.iterrows():\n    eng = row[\"eng\"]\n    ara = row[\"ara\"]\n    pred = translate(eng)\n    print(f\"\\nExample {i+1}\")\n    print(f\"English   : {eng}\")\n    print(f\"Arabic    : {ara}\")\n    print(f\"Predicted : {pred}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T16:52:14.143227Z","iopub.execute_input":"2025-09-11T16:52:14.143547Z","iopub.status.idle":"2025-09-11T16:52:30.253758Z","shell.execute_reply.started":"2025-09-11T16:52:14.143526Z","shell.execute_reply":"2025-09-11T16:52:30.253164Z"}},"outputs":[{"name":"stderr","text":"loading file vocab.txt\nloading file tokenizer.json\nloading file added_tokens.json\nloading file special_tokens_map.json\nloading file tokenizer_config.json\nloading file chat_template.jinja\nloading configuration file /kaggle/working/bert-encdec-eng-ara/checkpoint-8424/config.json\nModel config EncoderDecoderConfig {\n  \"architectures\": [\n    \"EncoderDecoderModel\"\n  ],\n  \"decoder\": {\n    \"_name_or_path\": \"bert-base-multilingual-cased\",\n    \"add_cross_attention\": true,\n    \"architectures\": [\n      \"BertForMaskedLM\"\n    ],\n    \"attention_probs_dropout_prob\": 0.1,\n    \"classifier_dropout\": null,\n    \"directionality\": \"bidi\",\n    \"hidden_act\": \"gelu\",\n    \"hidden_dropout_prob\": 0.1,\n    \"hidden_size\": 768,\n    \"initializer_range\": 0.02,\n    \"intermediate_size\": 3072,\n    \"is_decoder\": true,\n    \"layer_norm_eps\": 1e-12,\n    \"max_position_embeddings\": 512,\n    \"model_type\": \"bert\",\n    \"num_attention_heads\": 12,\n    \"num_hidden_layers\": 12,\n    \"pooler_fc_size\": 768,\n    \"pooler_num_attention_heads\": 12,\n    \"pooler_num_fc_layers\": 3,\n    \"pooler_size_per_head\": 128,\n    \"pooler_type\": \"first_token_transform\",\n    \"position_embedding_type\": \"absolute\",\n    \"torch_dtype\": \"float32\",\n    \"type_vocab_size\": 2,\n    \"use_cache\": true,\n    \"vocab_size\": 119547\n  },\n  \"decoder_start_token_id\": 101,\n  \"encoder\": {\n    \"_name_or_path\": \"bert-base-multilingual-cased\",\n    \"architectures\": [\n      \"BertForMaskedLM\"\n    ],\n    \"attention_probs_dropout_prob\": 0.1,\n    \"classifier_dropout\": null,\n    \"directionality\": \"bidi\",\n    \"hidden_act\": \"gelu\",\n    \"hidden_dropout_prob\": 0.1,\n    \"hidden_size\": 768,\n    \"initializer_range\": 0.02,\n    \"intermediate_size\": 3072,\n    \"layer_norm_eps\": 1e-12,\n    \"max_position_embeddings\": 512,\n    \"model_type\": \"bert\",\n    \"num_attention_heads\": 12,\n    \"num_hidden_layers\": 12,\n    \"pooler_fc_size\": 768,\n    \"pooler_num_attention_heads\": 12,\n    \"pooler_num_fc_layers\": 3,\n    \"pooler_size_per_head\": 128,\n    \"pooler_type\": \"first_token_transform\",\n    \"position_embedding_type\": \"absolute\",\n    \"torch_dtype\": \"float32\",\n    \"type_vocab_size\": 2,\n    \"use_cache\": true,\n    \"vocab_size\": 119547\n  },\n  \"eos_token_id\": 102,\n  \"is_encoder_decoder\": true,\n  \"max_length\": null,\n  \"model_type\": \"encoder-decoder\",\n  \"pad_token_id\": 0,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.52.4\",\n  \"vocab_size\": 119547\n}\n\nloading weights file /kaggle/working/bert-encdec-eng-ara/checkpoint-8424/model.safetensors\nGenerate config GenerationConfig {\n  \"decoder_start_token_id\": 101,\n  \"eos_token_id\": 102,\n  \"pad_token_id\": 0\n}\n\nInstantiating BertModel model under default dtype torch.float32.\nInstantiating BertLMHeadModel model under default dtype torch.float32.\nGenerate config GenerationConfig {\n  \"pad_token_id\": 0\n}\n\nAll model checkpoint weights were used when initializing EncoderDecoderModel.\n\nAll the weights of EncoderDecoderModel were initialized from the model checkpoint at /kaggle/working/bert-encdec-eng-ara/checkpoint-8424.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use EncoderDecoderModel for predictions without further training.\nloading configuration file /kaggle/working/bert-encdec-eng-ara/checkpoint-8424/generation_config.json\nGenerate config GenerationConfig {\n  \"max_length\": 64,\n  \"pad_token_id\": 0\n}\n\n","output_type":"stream"},{"name":"stdout","text":"\nExample 1\nEnglish   : Do you have a friend named Tom?\nArabic    : هل لديك صديق يسمى توم ؟\nPredicted : \n\nExample 2\nEnglish   : She called me in the afternoon.\nArabic    : اتصلت بي بعد الظهر.\nPredicted : \n\nExample 3\nEnglish   : I had nothing else to do.\nArabic    : لم يكن لديّ أيّ شيء آخر أقوم به.\nPredicted : \n\nExample 4\nEnglish   : I said I would make her happy.\nArabic    : قلتُ أني سأسعدها.\nPredicted : \n\nExample 5\nEnglish   : He asked us to help him.\nArabic    : طلب منا المساعدة.\nPredicted : \n\nExample 6\nEnglish   : All of us should go.\nArabic    : علينا جميعا أن نذهب.\nPredicted : علينا جميعا ان نذهب\n\nExample 7\nEnglish   : That was years ago.\nArabic    : حصل ذلك منذ سنوات عدة.\nPredicted : \n\nExample 8\nEnglish   : The doctor took his pulse.\nArabic    : قاس الطبيب نبضه.\nPredicted : \n\nExample 9\nEnglish   : This story is based on a true story.\nArabic    : هذه القصة مُستمّدة من قصّةٍ واقعية.\nPredicted : \n\nExample 10\nEnglish   : What are you up to tomorrow afternoon?\nArabic    : ماذا عندك بعد ظهر غد؟\nPredicted : \n\nExample 11\nEnglish   : You will never get bored in her company.\nArabic    : لن تشعر أبداً بالملل في صحبتها.\nPredicted : \n\nExample 12\nEnglish   : I studied in Boston from 2003 to 2007.\nArabic    : درست في بوسطون من عام ألفين و ثلاثة إلى عام ألفين و سبعة للميلاد.\nPredicted : درست في بوسطون من عام الفين و ثلاثه الي عام الفين و سبعه للميلاد\n\nExample 13\nEnglish   : I'm not thirsty.\nArabic    : لا أشعر بالعطش.\nPredicted : \n\nExample 14\nEnglish   : I know how to survive.\nArabic    : انا اعرف كيفية النجاة\nPredicted : \n\nExample 15\nEnglish   : We are teachers.\nArabic    : نحن معلمون.\nPredicted : \n\nExample 16\nEnglish   : I've never seen a car this old in such good condition.\nArabic    : لم أرى سيارة بهذا القدم بهذه الحالة الجيدة.\nPredicted : \n\nExample 17\nEnglish   : Did you discuss any of the issues on our list?\nArabic    : هل ناقشت أيًا من المسائل في قائمتنا ؟\nPredicted : \n\nExample 18\nEnglish   : She showed me around the campus.\nArabic    : أعطتني جولة في الحرم الجامعي.\nPredicted : \n\nExample 19\nEnglish   : I really feel sorry for Tom.\nArabic    : أحزن كثيرًا على سامي.\nPredicted : \n\nExample 20\nEnglish   : I think you're right.\nArabic    : أعتقد أنك صائب.\nPredicted : \n","output_type":"stream"}],"execution_count":10},{"id":"c33640e4-a74f-4469-84e5-b07a0f2f9f94","cell_type":"code","source":"!zip -r bert_checkpoint.zip /kaggle/working/bert-encdec-eng-ara/checkpoint-8424","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:02:42.430623Z","iopub.execute_input":"2025-09-11T17:02:42.431549Z","iopub.status.idle":"2025-09-11T17:06:12.271466Z","shell.execute_reply.started":"2025-09-11T17:02:42.431509Z","shell.execute_reply":"2025-09-11T17:06:12.270560Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/bert-encdec-eng-ara/checkpoint-8424/ (stored 0%)\n  adding: kaggle/working/bert-encdec-eng-ara/checkpoint-8424/scheduler.pt (deflated 57%)\n  adding: kaggle/working/bert-encdec-eng-ara/checkpoint-8424/special_tokens_map.json (deflated 42%)\n  adding: kaggle/working/bert-encdec-eng-ara/checkpoint-8424/model.safetensors","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":" (deflated 7%)\n  adding: kaggle/working/bert-encdec-eng-ara/checkpoint-8424/generation_config.json (deflated 14%)\n  adding: kaggle/working/bert-encdec-eng-ara/checkpoint-8424/vocab.txt (deflated 45%)\n  adding: kaggle/working/bert-encdec-eng-ara/checkpoint-8424/tokenizer.json (deflated 67%)\n  adding: kaggle/working/bert-encdec-eng-ara/checkpoint-8424/trainer_state.json (deflated 80%)\n  adding: kaggle/working/bert-encdec-eng-ara/checkpoint-8424/rng_state.pth (deflated 25%)\n  adding: kaggle/working/bert-encdec-eng-ara/checkpoint-8424/config.json (deflated 75%)\n  adding: kaggle/working/bert-encdec-eng-ara/checkpoint-8424/tokenizer_config.json (deflated 75%)\n  adding: kaggle/working/bert-encdec-eng-ara/checkpoint-8424/training_args.bin (deflated 52%)\n  adding: kaggle/working/bert-encdec-eng-ara/checkpoint-8424/scaler.pt (deflated 60%)\n  adding: kaggle/working/bert-encdec-eng-ara/checkpoint-8424/optimizer.pt (deflated 30%)\n","output_type":"stream"}],"execution_count":18},{"id":"5995d6e4-14bb-4e8f-a242-fc2f56e0a5d4","cell_type":"code","source":"# rm -rf /kaggle/working/bert-encdec-eng-ara/checkpoint-7500\n# rm -rf /kaggle/working/bert-encdec-eng-ara/checkpoint-8000\n# !rm -rf /kaggle/working/bert-encdec-eng-ara/checkpoint-8424\n# !rm -f /kaggle/working/bert_checkpoint.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:09:30.858920Z","iopub.execute_input":"2025-09-11T17:09:30.859505Z","iopub.status.idle":"2025-09-11T17:09:32.062757Z","shell.execute_reply.started":"2025-09-11T17:09:30.859482Z","shell.execute_reply":"2025-09-11T17:09:32.061485Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":20},{"id":"11e564b5-9991-4d3d-9ea5-dcdc84fa6d44","cell_type":"code","source":"!zip -r bert_encdec_eng_ara.zip ./bert-encdec-eng-ara","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:09:57.462940Z","iopub.execute_input":"2025-09-11T17:09:57.463317Z","iopub.status.idle":"2025-09-11T17:11:19.790813Z","shell.execute_reply.started":"2025-09-11T17:09:57.463288Z","shell.execute_reply":"2025-09-11T17:11:19.790006Z"}},"outputs":[{"name":"stdout","text":"  adding: bert-encdec-eng-ara/ (stored 0%)\n  adding: bert-encdec-eng-ara/special_tokens_map.json (deflated 42%)\n  adding: bert-encdec-eng-ara/model.safetensors","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":" (deflated 7%)\n  adding: bert-encdec-eng-ara/generation_config.json (deflated 14%)\n  adding: bert-encdec-eng-ara/vocab.txt (deflated 45%)\n  adding: bert-encdec-eng-ara/tokenizer.json (deflated 67%)\n  adding: bert-encdec-eng-ara/config.json (deflated 75%)\n  adding: bert-encdec-eng-ara/tokenizer_config.json (deflated 75%)\n  adding: bert-encdec-eng-ara/training_args.bin (deflated 52%)\n","output_type":"stream"}],"execution_count":21},{"id":"dce1f93c-388c-49dc-bd46-bbb97c61e6ef","cell_type":"markdown","source":"---","metadata":{}},{"id":"d595cacd-7063-45a1-b5c2-12dc2a3ec487","cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:17:40.391295Z","iopub.execute_input":"2025-09-11T17:17:40.392140Z","iopub.status.idle":"2025-09-11T17:17:40.417714Z","shell.execute_reply.started":"2025-09-11T17:17:40.392086Z","shell.execute_reply":"2025-09-11T17:17:40.416931Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bd5dd8d24974e29a151a284fbb3777e"}},"metadata":{}}],"execution_count":22},{"id":"819f3972-494f-49c5-bbc7-7a599cee3a55","cell_type":"code","source":"from huggingface_hub import create_repo\n\n# replace with your username\ncreate_repo(\"bert-encdec-eng-ara\", private=True)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:20:32.083494Z","iopub.execute_input":"2025-09-11T17:20:32.083757Z","iopub.status.idle":"2025-09-11T17:20:32.745778Z","shell.execute_reply.started":"2025-09-11T17:20:32.083736Z","shell.execute_reply":"2025-09-11T17:20:32.745190Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"RepoUrl('https://huggingface.co/idrisskh/bert-encdec-eng-ara', endpoint='https://huggingface.co', repo_type='model', repo_id='idrisskh/bert-encdec-eng-ara')"},"metadata":{}}],"execution_count":23},{"id":"f1c981d4-05d7-4dc3-ace3-1429ab2c3e3c","cell_type":"code","source":"from huggingface_hub import upload_folder\n\nupload_folder(\n    repo_id=\"idrisskh/bert-encdec-eng-ara\",  \n    folder_path=\"./bert-encdec-eng-ara\",       \n    path_in_repo=\".\"                             \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:21:19.140697Z","iopub.execute_input":"2025-09-11T17:21:19.140999Z","iopub.status.idle":"2025-09-11T17:21:39.405262Z","shell.execute_reply.started":"2025-09-11T17:21:19.140977Z","shell.execute_reply":"2025-09-11T17:21:39.404446Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Uploading...:   0%|          | 0.00/1.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dee9b3d6c1b9417db451192f5f9ca490"}},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/idrisskh/bert-encdec-eng-ara/commit/c2cb31b63f59217a3d2a68d6079aa5269cf119f7', commit_message='Upload folder using huggingface_hub', commit_description='', oid='c2cb31b63f59217a3d2a68d6079aa5269cf119f7', pr_url=None, repo_url=RepoUrl('https://huggingface.co/idrisskh/bert-encdec-eng-ara', endpoint='https://huggingface.co', repo_type='model', repo_id='idrisskh/bert-encdec-eng-ara'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":24},{"id":"f783eb82-062f-4612-834a-f7e640a525e0","cell_type":"code","source":"from transformers import AutoTokenizer, EncoderDecoderModel\n\n# -------------------------\n# Load model + tokenizer\n# -------------------------\n\nmodel_name = \"idrisskh/bert-encdec-eng-ara\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = EncoderDecoderModel.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:23:39.038452Z","iopub.execute_input":"2025-09-11T17:23:39.038936Z","iopub.status.idle":"2025-09-11T17:23:47.683977Z","shell.execute_reply.started":"2025-09-11T17:23:39.038914Z","shell.execute_reply":"2025-09-11T17:23:47.683439Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.22k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9ded2d060f44f44ae635aae3182026f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77fc036ce1a54b60832cea2b39494bb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.92M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e393e02b8ec541e4a9b6c01f407735d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9a8345a9f924372b31012d0064c2cdd"}},"metadata":{}},{"name":"stderr","text":"loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--idrisskh--bert-encdec-eng-ara/snapshots/c2cb31b63f59217a3d2a68d6079aa5269cf119f7/vocab.txt\nloading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--idrisskh--bert-encdec-eng-ara/snapshots/c2cb31b63f59217a3d2a68d6079aa5269cf119f7/tokenizer.json\nloading file added_tokens.json from cache at None\nloading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--idrisskh--bert-encdec-eng-ara/snapshots/c2cb31b63f59217a3d2a68d6079aa5269cf119f7/special_tokens_map.json\nloading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--idrisskh--bert-encdec-eng-ara/snapshots/c2cb31b63f59217a3d2a68d6079aa5269cf119f7/tokenizer_config.json\nloading file chat_template.jinja from cache at None\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3d0e5ccaa004992801435fcb7ddc4fc"}},"metadata":{}},{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--idrisskh--bert-encdec-eng-ara/snapshots/c2cb31b63f59217a3d2a68d6079aa5269cf119f7/config.json\nModel config EncoderDecoderConfig {\n  \"architectures\": [\n    \"EncoderDecoderModel\"\n  ],\n  \"decoder\": {\n    \"_name_or_path\": \"bert-base-multilingual-cased\",\n    \"add_cross_attention\": true,\n    \"architectures\": [\n      \"BertForMaskedLM\"\n    ],\n    \"attention_probs_dropout_prob\": 0.1,\n    \"classifier_dropout\": null,\n    \"directionality\": \"bidi\",\n    \"hidden_act\": \"gelu\",\n    \"hidden_dropout_prob\": 0.1,\n    \"hidden_size\": 768,\n    \"initializer_range\": 0.02,\n    \"intermediate_size\": 3072,\n    \"is_decoder\": true,\n    \"layer_norm_eps\": 1e-12,\n    \"max_position_embeddings\": 512,\n    \"model_type\": \"bert\",\n    \"num_attention_heads\": 12,\n    \"num_hidden_layers\": 12,\n    \"pooler_fc_size\": 768,\n    \"pooler_num_attention_heads\": 12,\n    \"pooler_num_fc_layers\": 3,\n    \"pooler_size_per_head\": 128,\n    \"pooler_type\": \"first_token_transform\",\n    \"position_embedding_type\": \"absolute\",\n    \"torch_dtype\": \"float32\",\n    \"type_vocab_size\": 2,\n    \"use_cache\": true,\n    \"vocab_size\": 119547\n  },\n  \"decoder_start_token_id\": 101,\n  \"encoder\": {\n    \"_name_or_path\": \"bert-base-multilingual-cased\",\n    \"architectures\": [\n      \"BertForMaskedLM\"\n    ],\n    \"attention_probs_dropout_prob\": 0.1,\n    \"classifier_dropout\": null,\n    \"directionality\": \"bidi\",\n    \"hidden_act\": \"gelu\",\n    \"hidden_dropout_prob\": 0.1,\n    \"hidden_size\": 768,\n    \"initializer_range\": 0.02,\n    \"intermediate_size\": 3072,\n    \"layer_norm_eps\": 1e-12,\n    \"max_position_embeddings\": 512,\n    \"model_type\": \"bert\",\n    \"num_attention_heads\": 12,\n    \"num_hidden_layers\": 12,\n    \"pooler_fc_size\": 768,\n    \"pooler_num_attention_heads\": 12,\n    \"pooler_num_fc_layers\": 3,\n    \"pooler_size_per_head\": 128,\n    \"pooler_type\": \"first_token_transform\",\n    \"position_embedding_type\": \"absolute\",\n    \"torch_dtype\": \"float32\",\n    \"type_vocab_size\": 2,\n    \"use_cache\": true,\n    \"vocab_size\": 119547\n  },\n  \"eos_token_id\": 102,\n  \"is_encoder_decoder\": true,\n  \"max_length\": null,\n  \"model_type\": \"encoder-decoder\",\n  \"pad_token_id\": 0,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.52.4\",\n  \"vocab_size\": 119547\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfec601641fc46b8846de0f823fab318"}},"metadata":{}},{"name":"stderr","text":"loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--idrisskh--bert-encdec-eng-ara/snapshots/c2cb31b63f59217a3d2a68d6079aa5269cf119f7/model.safetensors\nGenerate config GenerationConfig {\n  \"decoder_start_token_id\": 101,\n  \"eos_token_id\": 102,\n  \"pad_token_id\": 0\n}\n\nInstantiating BertModel model under default dtype torch.float32.\nInstantiating BertLMHeadModel model under default dtype torch.float32.\nGenerate config GenerationConfig {\n  \"pad_token_id\": 0\n}\n\nAll model checkpoint weights were used when initializing EncoderDecoderModel.\n\nAll the weights of EncoderDecoderModel were initialized from the model checkpoint at idrisskh/bert-encdec-eng-ara.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use EncoderDecoderModel for predictions without further training.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/110 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3a6972a7ae14fe99475273b9f1863a5"}},"metadata":{}},{"name":"stderr","text":"loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--idrisskh--bert-encdec-eng-ara/snapshots/c2cb31b63f59217a3d2a68d6079aa5269cf119f7/generation_config.json\nGenerate config GenerationConfig {\n  \"max_length\": 64,\n  \"pad_token_id\": 0\n}\n\n","output_type":"stream"}],"execution_count":25},{"id":"9af61a23-8510-4c81-85ef-a6be11dd3954","cell_type":"code","source":"import pandas as pd\nimport torch\n\n# Fix missing config values\nif model.config.decoder_start_token_id is None:\n    model.config.decoder_start_token_id = tokenizer.cls_token_id or tokenizer.bos_token_id\nif model.config.eos_token_id is None:\n    model.config.eos_token_id = tokenizer.sep_token_id or tokenizer.eos_token_id\nif model.config.pad_token_id is None:\n    model.config.pad_token_id = tokenizer.pad_token_id\n\n\nprint(\"CLS:\", tokenizer.cls_token_id)\nprint(\"SEP:\", tokenizer.sep_token_id)\nprint(\"PAD:\", tokenizer.pad_token_id)\nprint(\"Decoder start:\", model.config.decoder_start_token_id)\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Force set special tokens for generation\nmodel.config.decoder_start_token_id = tokenizer.cls_token_id or 101\nmodel.config.eos_token_id = tokenizer.sep_token_id or 102\nmodel.config.pad_token_id = tokenizer.pad_token_id or 0\n\n# -------------------------\n# Load dataset\n# -------------------------\nfile_path = \"/kaggle/input/eng-ara/eng-ara.txt\" \ndf = pd.read_csv(file_path, sep=\"\\t\", header=None, usecols=[0,1], names=[\"eng\",\"ara\"])\n\n# Take 20 random samples\nsample_df = df.sample(20, random_state=42).reset_index(drop=True)\n\n# -------------------------\n# Prediction function\n# -------------------------\ndef translate(sentence, max_len=64):\n    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n    \n    outputs = model.generate(\n        **inputs,\n        max_length=max_len,\n        num_beams=5,                # beam search (better than greedy)\n        early_stopping=True,\n        decoder_start_token_id=tokenizer.cls_token_id or model.config.decoder_start_token_id,\n        eos_token_id=tokenizer.sep_token_id or model.config.eos_token_id,\n        pad_token_id=tokenizer.pad_token_id or model.config.pad_token_id\n    )\n\n    pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return pred.strip()\n\n\n# -------------------------\n# Run predictions\n# -------------------------\nfor i, row in sample_df.iterrows():\n    eng = row[\"eng\"]\n    ara = row[\"ara\"]\n    pred = translate(eng)\n    print(f\"\\nExample {i+1}\")\n    print(f\"English   : {eng}\")\n    print(f\"Arabic    : {ara}\")\n    print(f\"Predicted : {pred}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-11T17:27:25.715232Z","iopub.execute_input":"2025-09-11T17:27:25.715511Z","iopub.status.idle":"2025-09-11T17:27:34.155880Z","shell.execute_reply.started":"2025-09-11T17:27:25.715493Z","shell.execute_reply":"2025-09-11T17:27:34.155270Z"}},"outputs":[{"name":"stdout","text":"CLS: 101\nSEP: 102\nPAD: 0\nDecoder start: 101\n\nExample 1\nEnglish   : Do you have a friend named Tom?\nArabic    : هل لديك صديق يسمى توم ؟\nPredicted : هل لديك صديق توم ؟\n\nExample 2\nEnglish   : She called me in the afternoon.\nArabic    : اتصلت بي بعد الظهر.\nPredicted : اتصلت بي بعد الظهر\n\nExample 3\nEnglish   : I had nothing else to do.\nArabic    : لم يكن لديّ أيّ شيء آخر أقوم به.\nPredicted : لم يكن لدي اي شي اخر اقوم به\n\nExample 4\nEnglish   : I said I would make her happy.\nArabic    : قلتُ أني سأسعدها.\nPredicted : \n\nExample 5\nEnglish   : He asked us to help him.\nArabic    : طلب منا المساعدة.\nPredicted : طلب منا المساعده\n\nExample 6\nEnglish   : All of us should go.\nArabic    : علينا جميعا أن نذهب.\nPredicted : علينا جميعا ان نذهب\n\nExample 7\nEnglish   : That was years ago.\nArabic    : حصل ذلك منذ سنوات عدة.\nPredicted : كان ذلك منذ عده سنين\n\nExample 8\nEnglish   : The doctor took his pulse.\nArabic    : قاس الطبيب نبضه.\nPredicted : قاس الطبيب\n\nExample 9\nEnglish   : This story is based on a true story.\nArabic    : هذه القصة مُستمّدة من قصّةٍ واقعية.\nPredicted : هذه القصه مستمده من قصه واقعيه\n\nExample 10\nEnglish   : What are you up to tomorrow afternoon?\nArabic    : ماذا عندك بعد ظهر غد؟\nPredicted : \n\nExample 11\nEnglish   : You will never get bored in her company.\nArabic    : لن تشعر أبداً بالملل في صحبتها.\nPredicted : لن تتعامل معها ابدا\n\nExample 12\nEnglish   : I studied in Boston from 2003 to 2007.\nArabic    : درست في بوسطون من عام ألفين و ثلاثة إلى عام ألفين و سبعة للميلاد.\nPredicted : درست في بوسطون من عام الفين و ثلاثه الي عام الفين و سبعه للميلاد\n\nExample 13\nEnglish   : I'm not thirsty.\nArabic    : لا أشعر بالعطش.\nPredicted : انا لست عطشانا\n\nExample 14\nEnglish   : I know how to survive.\nArabic    : انا اعرف كيفية النجاة\nPredicted : انا اعرف كيف ننتظر\n\nExample 15\nEnglish   : We are teachers.\nArabic    : نحن معلمون.\nPredicted : نحن معلمون\n\nExample 16\nEnglish   : I've never seen a car this old in such good condition.\nArabic    : لم أرى سيارة بهذا القدم بهذه الحالة الجيدة.\nPredicted : لم اركض سياره كبيره في حالته هذا النوع من السياره\n\nExample 17\nEnglish   : Did you discuss any of the issues on our list?\nArabic    : هل ناقشت أيًا من المسائل في قائمتنا ؟\nPredicted : هل ناقشت ايا من المسايل في قايمتنا ؟\n\nExample 18\nEnglish   : She showed me around the campus.\nArabic    : أعطتني جولة في الحرم الجامعي.\nPredicted : اعطتني جوله في الحرم الجامعي\n\nExample 19\nEnglish   : I really feel sorry for Tom.\nArabic    : أحزن كثيرًا على سامي.\nPredicted : \n\nExample 20\nEnglish   : I think you're right.\nArabic    : أعتقد أنك صائب.\nPredicted : اظن انك محق\n","output_type":"stream"}],"execution_count":27}]}